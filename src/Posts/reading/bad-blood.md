This story about Elizabeth Holmes' Theranos is a powerful one. Past the gripping tale of Holmes' blatant fraud, a much larger and stronger lesson lurks... one warning the fast-and-loose culture of Silicon Valley that the world at large isn't as easily patchable as software.

In that sense, it could read as a parable warning against entrepreneurial hubris and examining the ethics of innovation. Are there industries that _can't_ be rushed into? What's the maximum level of risk to the customer that we should deem acceptable? How much transparency should be expected of new and innovative companies' methodology?

Theranos' rise and fall should be kept firmly in the minds of those in the tech world who seek to overturn industries where significant harm can be done. What if something like this happened with infrastructure? In education? Actions have consequences, and—unlike in software—a quick change can't undo long-lasting harm.

Thankfully, tech companies seem to act more responsibly when explicitly trusted with customers' lives; Tesla's cars are famously safe, for instance. But what about when harm isn't that clear-cut, as in the case of Google and Facebook? Leaked passwords, hacked chats, concentrated hate... those hurt people too. Silicon Valley in general—not just Theranos—has a problematic habit of moving fast and breaking things, only reluctantly taking responsibility for their actions' negative impacts when shamed into a corner after something horrible happens.

And the final blame comes down squarely on that culture. Sure, Holmes was a fraud—but the fact that the immediate financial and cultural environments of the tech world enabled her to get _so_ far without question is absolutely contemptible.
